<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Neural Network (Deep Learning): src/cpp/neuralnetwork.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Neural Network (Deep Learning)
   </div>
   <div id="projectbrief">Mini-project 1</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="dir_dfdbda394c3f7a3aa55229f33a559c41.html">cpp</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">neuralnetwork.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="neuralnetwork_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="preprocessor">#include &quot;../headers/NeuralNetwork.h&quot;</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#accce4a7728e89a009a9d4ca1758c9b9d">    3</a></span>&#160;<a class="code" href="classNeuralNetwork.html#accce4a7728e89a009a9d4ca1758c9b9d">NeuralNetwork::NeuralNetwork</a>()</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;{</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;        <a class="code" href="classNeuralNetwork.html#a5009762781007f09860915f307701a60">m_flagSwapped</a> = <span class="keyword">false</span>;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;}</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a3c92371fb8eb9363460223b67f2716f4">    8</a></span>&#160;<span class="keywordtype">double</span> <a class="code" href="classNeuralNetwork.html#a3c92371fb8eb9363460223b67f2716f4">NeuralNetwork::getLSError</a>(<span class="keywordtype">double</span> targ, <span class="keywordtype">double</span> pred, <span class="keywordtype">int</span> jj){</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;        <span class="comment">// Calculate the squared error for the target and prediction</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classNeuralNetwork.html#a296fef6f667d2bcf1080a16c8c3aceb2">m_objective</a>.<a class="code" href="classObjective.html#a91b745efca74c55eb1415bdc101c0c8c">getLSError</a>(targ,  pred,  jj);        </div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;}</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#aeccccbe1b61dec7e4e76bd55bad7e591">   15</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#aeccccbe1b61dec7e4e76bd55bad7e591">NeuralNetwork::swapWeights</a>(){</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;        <span class="comment">// Swap the weights (current with the saved copy which gives minimal validation error)</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;        <a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>.swap(<a class="code" href="classNeuralNetwork.html#a9ac6bc441d6e2bfe7521d0b23ac8efdb">m_weightsMinCp</a>);</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;}</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a30196e8390fead450b9495b3a782b198">   21</a></span>&#160;<span class="keywordtype">int</span> <a class="code" href="classNeuralNetwork.html#a30196e8390fead450b9495b3a782b198">NeuralNetwork::makeWeightCpy</a>() {  </div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;        <span class="comment">// Save the weights which give the minimum validation error </span></div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;        <span class="keywordflow">for</span>( <span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1; ++ii) {</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1); ++jj) {</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> kk= 0; kk&lt;<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii)+1; ++kk) {</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;                    <a class="code" href="classNeuralNetwork.html#a9ac6bc441d6e2bfe7521d0b23ac8efdb">m_weightsMinCp</a>[ii][jj][kk] = <a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>[ii][jj][kk];</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;                }</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;        }</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;        }</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;        <span class="comment">// Set the validation flag to true</span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;        <a class="code" href="classNeuralNetwork.html#a5009762781007f09860915f307701a60">m_flagSwapped</a> = <span class="keyword">true</span>;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;    <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;}</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div><div class="line"><a name="l00040"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a1d0b90f44982811b3e28e3b9a4dfa810">   40</a></span>&#160;<span class="keywordtype">int</span> <a class="code" href="classNeuralNetwork.html#a1d0b90f44982811b3e28e3b9a4dfa810">NeuralNetwork::setDropOut</a>(){</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;        <span class="comment">// Shuffle the drop out array for every layer (indicates which units will be missing)</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1; ++ii){</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;                std::random_shuffle(<a class="code" href="classNeuralNetwork.html#a456d6c273c0bd4f160f4d20f8b26f37b">m_dropOutVec</a>[ii].begin(), <a class="code" href="classNeuralNetwork.html#a456d6c273c0bd4f160f4d20f8b26f37b">m_dropOutVec</a>[ii].end());</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;        }</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;        <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;}</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;</div><div class="line"><a name="l00049"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#ae3d909ef30a5c179a236571e126aa841">   49</a></span>&#160;<span class="keywordtype">int</span> <a class="code" href="classNeuralNetwork.html#ae3d909ef30a5c179a236571e126aa841">NeuralNetwork::feedforward</a>(<span class="keywordtype">int</span> mb){</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;        <span class="comment">// Go through every layer</span></div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> kk = 0; kk &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1; ++kk){</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;                <span class="comment">// Go through every unit in current+1 layer</span></div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk+1); ++jj){</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;                        <span class="comment">// Get the dot product (going through the current layer)</span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;                        <a class="code" href="classNeuralNetwork.html#af8a0997a14c97e1fb6ef97d3c132f808">dotProductProp</a>(mb,kk,jj);</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        </div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;                        <span class="comment">// If stats flag is enabled and we are in the encoder</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;                        <span class="keywordflow">if</span> (<a class="code" href="classNeuralNetwork.html#accd035b1b93fd424025aeb4b40a31394">m_statsFlag</a> == <a class="code" href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5ab40dedbb237d7d5e7aeef947a8f1cbc6">enabled</a> &amp;&amp; kk&lt;<a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-2){</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;                              <span class="comment">// Want to see what each hidden unit output is</span></div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;                              <a class="code" href="classNeuralNetwork.html#a15f7c03ca694dadc97a4290711ca2101">m_statsHiddenUnits</a>[kk][jj] += (<a class="code" href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">getLayerUOutput</a>(mb,kk+1,jj)/(float)<a class="code" href="classNeuralNetwork.html#ae4f1fb12e7f5df8dac69abda6fe4d141">m_itTest</a>);</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;                        }</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;            }</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    }</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;}</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;</div><div class="line"><a name="l00072"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a82af0b25c1099ac3818a36911b63e8db">   72</a></span>&#160;<span class="keywordtype">int</span> <a class="code" href="classNeuralNetwork.html#a82af0b25c1099ac3818a36911b63e8db">NeuralNetwork::feedforwardNodeParallelCompSparse</a>(<span class="keywordtype">int</span> mb){</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;        <span class="comment">// Counters are private thus every thread updates its own local copy and thus explicit synchronization is required</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;        <span class="keywordtype">int</span> kk = 0;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        <span class="comment">// Go through every layer</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;    <span class="keywordflow">while</span>(kk &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-2){</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;                <span class="comment">// Go through every unit in current+1 layer</span></div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="preprocessor">                #pragma omp for schedule(guided)</span></div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk+1); ++jj){</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;                        <span class="comment">// Get the dot product (going through the current layer)</span></div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;                        <a class="code" href="classNeuralNetwork.html#af8a0997a14c97e1fb6ef97d3c132f808">dotProductProp</a>(mb,kk,jj);</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;                        <span class="comment">// Get the average of all units used in regularisation for a sparse autoencoder</span></div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;                        <a class="code" href="classNeuralNetwork.html#a257969584b79a83070b07462b1ec7fb2">m_avUnits</a>[jj] += (<a class="code" href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">getLayerUOutput</a>(mb,kk+1,jj)/(float)<a class="code" href="classNeuralNetwork.html#ad29fd15c4f0fc4c8fd214b4e815093b9">m_miniBatch</a>);</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;            }</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;                ++kk;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    }</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;}</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;</div><div class="line"><a name="l00093"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#aad8fc497e54c397d3e4e91376e02e939">   93</a></span>&#160;<span class="keywordtype">int</span> <a class="code" href="classNeuralNetwork.html#aad8fc497e54c397d3e4e91376e02e939">NeuralNetwork::feedforwardNodeParallel</a>(<span class="keywordtype">int</span> mb){</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;        <span class="comment">// Counters are private thus every thread updates its own local copy and thus explicit synchronization is required</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        <span class="keywordtype">int</span> kk = 0;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;        <span class="comment">// Go through every layer</span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;    <span class="keywordflow">while</span>(kk &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1){</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;                <span class="comment">// Go through every unit in current+1 layer</span></div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;<span class="preprocessor">                #pragma omp for schedule(guided)</span></div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk+1); ++jj){</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;                        <a class="code" href="classNeuralNetwork.html#af8a0997a14c97e1fb6ef97d3c132f808">dotProductProp</a>(mb,kk,jj);</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;            }</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;                ++kk;</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;    }</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    <span class="keywordflow">return</span> 0;</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;}</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;</div><div class="line"><a name="l00111"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#adca7f84b7b063acebef819bae1abbaf7">  111</a></span>&#160;<span class="keywordtype">double</span> <a class="code" href="classNeuralNetwork.html#adca7f84b7b063acebef819bae1abbaf7">NeuralNetwork::dotProduct</a>(<span class="keywordtype">int</span> mb, <span class="keywordtype">int</span> kk,<span class="keywordtype">int</span> jj){</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;        <span class="keywordtype">double</span> tmp = 0.0;</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;        <span class="comment">//Get the dot product of the neurons in the kk layer with associated weights</span></div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk)+1; ++ii){</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;            tmp += <a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>[kk][jj][ii]*<a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[mb][kk]-&gt;getUnitOutput(ii);</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;        }</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;        <span class="comment">// Return only real values</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;        <span class="keywordflow">return</span> tmp*<a class="code" href="classNeuralNetwork.html#a456d6c273c0bd4f160f4d20f8b26f37b">m_dropOutVec</a>[kk][jj];</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;}</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#af8a0997a14c97e1fb6ef97d3c132f808">  124</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#af8a0997a14c97e1fb6ef97d3c132f808">NeuralNetwork::dotProductProp</a>(<span class="keywordtype">int</span> mb, <span class="keywordtype">int</span> kk,<span class="keywordtype">int</span> jj){</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;     <span class="comment">//Propagate the dot product throught the non-linearity</span></div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;     <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[mb][kk+1]-&gt;setLayerUOutProp(jj,<a class="code" href="classNeuralNetwork.html#adca7f84b7b063acebef819bae1abbaf7">dotProduct</a>(mb,kk,jj));</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;}</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;</div><div class="line"><a name="l00133"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#aff3f167f69f75a74ce3c425b8783d321">  133</a></span>&#160;<span class="keywordtype">double</span> <a class="code" href="classNeuralNetwork.html#aff3f167f69f75a74ce3c425b8783d321">NeuralNetwork::deltaComputeNodeParallel</a> (<span class="keywordtype">int</span> mb){</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;        <span class="keywordtype">int</span>  tid = omp_get_thread_num();</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;    <span class="keywordtype">double</span> errorder, erroro = 0.0;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;        <span class="comment">// Set the indeces to not to compute them in every iteration</span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    <span class="keywordtype">int</span> outLayer=<a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1;</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;        <span class="keywordtype">int</span> kk = (outLayer-1);</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;        <span class="comment">//Go through the last layer</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;<span class="preprocessor">        #pragma omp for schedule(guided)</span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(outLayer); ++jj){</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;                <span class="comment">// Get the error der (1 - backprop, jj - unit, delta, output*mask_value)</span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;                errorder = <a class="code" href="classNeuralNetwork.html#a296fef6f667d2bcf1080a16c8c3aceb2">m_objective</a>.<a class="code" href="classObjective.html#a83f3cc1fe6d1fefe00b06eb5d27b4e6e">objective</a>(1,jj,</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;                                                 <a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,outLayer,jj),</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;                                                 <a class="code" href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">getLayerUOutput</a>(mb,outLayer,jj))*<a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,0,jj);</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;                <span class="comment">// Get the error between prediction and target</span></div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;        erroro = erroro+ <a class="code" href="classNeuralNetwork.html#a296fef6f667d2bcf1080a16c8c3aceb2">m_objective</a>.<a class="code" href="classObjective.html#a83f3cc1fe6d1fefe00b06eb5d27b4e6e">objective</a>(0,</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;                                                       <a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,outLayer,jj),</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;                                                       <a class="code" href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">getLayerUOutput</a>(mb,outLayer,jj))*<a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,0,jj);</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;                </div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;                <span class="comment">// Update the delta of the mini-batch mb, in the last layer outLayer, in the unit jj, with val</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;                <a class="code" href="classNeuralNetwork.html#a2a84fe4a996154130853f031c6e475aa">setLayerUDelta</a>(mb,</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;                               outLayer,</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;                               jj,</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;                               errorder*<a class="code" href="classNeuralNetwork.html#a9d80cfaedb341a1a94e5b932665904d4">backPropagateU</a>(mb,outLayer,jj));</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;        }</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;        <span class="comment">// Array holds the error in the locations of the thread ids</span></div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;        <a class="code" href="classNeuralNetwork.html#ac447314a2315cd10f63b0b330857024a">m_sumDelta</a>[tid] = erroro;</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;        <span class="comment">// Sum all the errors from the split workload in serial (cannot use reduction since all the variables are private)</span></div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="preprocessor">        #pragma omp barrier</span></div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;        <span class="keywordflow">if</span> (tid==0){</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> gg = 1; gg &lt; omp_get_num_threads(); ++gg){</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;                          <a class="code" href="classNeuralNetwork.html#ac447314a2315cd10f63b0b330857024a">m_sumDelta</a>[0] += <a class="code" href="classNeuralNetwork.html#ac447314a2315cd10f63b0b330857024a">m_sumDelta</a>[gg];</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;                          <a class="code" href="classNeuralNetwork.html#ac447314a2315cd10f63b0b330857024a">m_sumDelta</a>[gg] = 0.0;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;                }</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;        }</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;<span class="preprocessor">        #pragma omp barrier</span></div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        erroro= <a class="code" href="classNeuralNetwork.html#ac447314a2315cd10f63b0b330857024a">m_sumDelta</a>[0];</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;        <span class="keywordtype">double</span> sumDelta;</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;        <span class="comment">// Go through all the layers backwards</span></div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;    <span class="keywordflow">while</span> (kk &gt; 0){</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;                <span class="comment">// Go through the current layer</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;<span class="preprocessor">                #pragma omp for schedule(guided)</span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk)+1; ++jj){</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;                    sumDelta = 0.0;</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;                        <span class="comment">// Go through the layer closer to the output and comput the sum delta for the current unit in the current layer</span></div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;                        <span class="comment">// \sum delta(ii)*weights(ii,jj)</span></div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;                    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk+1); ++ii){</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;                                sumDelta = sumDelta+(<a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,kk+1,ii))*<a class="code" href="classNeuralNetwork.html#a660717474efe687f8b7b4bfadd643fee">getWeightO</a>(kk,ii,jj);</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;                    }</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;                        <span class="comment">// If there are 3 layers and current layer is the middle and we use a sparse autoencoder</span></div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;                        <span class="keywordflow">if</span> (kk == 1 &amp;&amp; outLayer == 2 &amp;&amp; <a class="code" href="classNeuralNetwork.html#a5ff4dd9b7b90474cce090c37d7127366">m_sparse</a> != 0.0){</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;                                sumDelta += <a class="code" href="classNeuralNetwork.html#a5ff4dd9b7b90474cce090c37d7127366">m_sparse</a>*(-<a class="code" href="classNeuralNetwork.html#ac6e586b8ab49ef7ca1f07dab6f197f6c">m_sparsityParameter</a>/<a class="code" href="classNeuralNetwork.html#a257969584b79a83070b07462b1ec7fb2">m_avUnits</a>[jj]+(1-<a class="code" href="classNeuralNetwork.html#ac6e586b8ab49ef7ca1f07dab6f197f6c">m_sparsityParameter</a>)/(1-<a class="code" href="classNeuralNetwork.html#a257969584b79a83070b07462b1ec7fb2">m_avUnits</a>[jj]));</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;                                <span class="comment"></span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;<span class="comment">                                ///m_avUnits[jj]=0.0; YOU CANNOT 0, beacuse the value is used in the next iteration</span></div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;<span class="comment"></span>                        }</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;                        <span class="comment">// Update the delta</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;                    <a class="code" href="classNeuralNetwork.html#a2a84fe4a996154130853f031c6e475aa">setLayerUDelta</a>(mb,kk,jj,sumDelta*<a class="code" href="classNeuralNetwork.html#a9d80cfaedb341a1a94e5b932665904d4">backPropagateU</a>(mb,kk,jj));</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;        }</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;                --kk;</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;    }</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;    <span class="keywordflow">return</span> erroro;</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;}</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;</div><div class="line"><a name="l00212"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a49f0a71b2cfd1bd2a4af986354fa103c">  212</a></span>&#160;<span class="keywordtype">double</span> <a class="code" href="classNeuralNetwork.html#a49f0a71b2cfd1bd2a4af986354fa103c">NeuralNetwork::deltaCompute</a>(<span class="keywordtype">int</span> mb){</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;        <span class="keywordtype">double</span> errorder;</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;        <span class="keywordtype">double</span> erroro = 0.0;</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;        <span class="keywordtype">int</span> outLayer = <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1;</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;        <span class="comment">//Go through the last layer</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(outLayer); ++jj){</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;                <span class="comment">// Get the error der (1 - backprop, jj - unit, delta, output*mask_value)</span></div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;                errorder = <a class="code" href="classNeuralNetwork.html#a296fef6f667d2bcf1080a16c8c3aceb2">m_objective</a>.<a class="code" href="classObjective.html#a83f3cc1fe6d1fefe00b06eb5d27b4e6e">objective</a>(1,<a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,outLayer,jj),<a class="code" href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">getLayerUOutput</a>(mb,outLayer,jj));</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;                <span class="comment">// Get the error between prediction and target</span></div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;        erroro = erroro+ <a class="code" href="classNeuralNetwork.html#a296fef6f667d2bcf1080a16c8c3aceb2">m_objective</a>.<a class="code" href="classObjective.html#a83f3cc1fe6d1fefe00b06eb5d27b4e6e">objective</a>(0,<a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,outLayer,jj),<a class="code" href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">getLayerUOutput</a>(mb,outLayer,jj));</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;                <span class="comment">// Update the delta of the mini-batch mb, in the last layer outLayer, in the unit jj, with val</span></div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;                <a class="code" href="classNeuralNetwork.html#a2a84fe4a996154130853f031c6e475aa">setLayerUDelta</a>(mb,outLayer,jj,errorder*<a class="code" href="classNeuralNetwork.html#a9d80cfaedb341a1a94e5b932665904d4">backPropagateU</a>(mb,outLayer,jj));</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;        }</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;        <span class="comment">// Go through all the layers backwards</span></div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> kk = (outLayer-1); kk &gt; 0; --kk){</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;                <span class="comment">// Go through the current layer</span></div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk)+1; ++jj){</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;                    <span class="keywordtype">double</span> sumdelta = 0.0;</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;                        <span class="comment">// Go through the layer closer to the output and comput the sum delta for the current unit in the current layer</span></div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;                        <span class="comment">// \sum delta(ii)*weights(ii,jj)</span></div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;                    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(kk+1); ++ii){</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;                                sumdelta = sumdelta+(<a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(mb,kk+1,ii))*<a class="code" href="classNeuralNetwork.html#a660717474efe687f8b7b4bfadd643fee">getWeightO</a>(kk,ii,jj);</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;                    }</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;                        <span class="comment">// Update the delta</span></div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;                    <a class="code" href="classNeuralNetwork.html#a2a84fe4a996154130853f031c6e475aa">setLayerUDelta</a>(mb,kk,jj,sumdelta*<a class="code" href="classNeuralNetwork.html#a9d80cfaedb341a1a94e5b932665904d4">backPropagateU</a>(mb,kk,jj));</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;            }</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;        }</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;    <span class="keywordflow">return</span> erroro;</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;}</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;</div><div class="line"><a name="l00251"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a9d80cfaedb341a1a94e5b932665904d4">  251</a></span>&#160;<span class="keywordtype">double</span> <a class="code" href="classNeuralNetwork.html#a9d80cfaedb341a1a94e5b932665904d4">NeuralNetwork::backPropagateU</a>(<span class="keywordtype">int</span> mb,<span class="keywordtype">int</span> la,<span class="keywordtype">int</span> ii){</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;        <span class="comment">//In the mini-batch mb, in the layer la, apply the derivative of the non-linearity to the units output</span></div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[mb][la]-&gt;unitBackPropagate(ii);</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;}</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;</div><div class="line"><a name="l00256"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#af0c6f4203d6c3b823a575954102bdf5d">  256</a></span>&#160;<span class="keywordtype">double</span> <a class="code" href="classNeuralNetwork.html#af0c6f4203d6c3b823a575954102bdf5d">NeuralNetwork::getGrad</a>(<span class="keywordtype">int</span> kk, <span class="keywordtype">int</span> jj, <span class="keywordtype">int</span> ii){</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;        <span class="comment">// Gradient = \sum delta*output for every mini-batch</span></div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;        <span class="keywordtype">double</span> grad = 0.0;</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ff = 0; ff &lt; <a class="code" href="classNeuralNetwork.html#ad29fd15c4f0fc4c8fd214b4e815093b9">m_miniBatch</a>; ++ff){</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;                grad += <a class="code" href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">getLayerUDelta</a>(ff,kk,jj)*<a class="code" href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">getLayerUOutput</a>(ff,kk-1,ii);</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;    }</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;        <span class="keywordflow">return</span> grad/(double)m_miniBatch;</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;                        </div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;}</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;</div><div class="line"><a name="l00267"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#ad5d0e3d069c7ce2fbde30161771ba507">  267</a></span>&#160;<span class="keywordtype">void</span>  <a class="code" href="classNeuralNetwork.html#ad5d0e3d069c7ce2fbde30161771ba507">NeuralNetwork::setLayerUOutput</a> (<span class="keywordtype">int</span> mb, <span class="keywordtype">int</span> la, <span class="keywordtype">int</span> u, <span class="keywordtype">double</span> val){</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;        <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[mb][la]-&gt;setUnitOutput(u,val);</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;}</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;</div><div class="line"><a name="l00271"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a2a84fe4a996154130853f031c6e475aa">  271</a></span>&#160;<span class="keywordtype">void</span>  <a class="code" href="classNeuralNetwork.html#a2a84fe4a996154130853f031c6e475aa">NeuralNetwork::setLayerUDelta</a>(<span class="keywordtype">int</span> mb, <span class="keywordtype">int</span> jj, <span class="keywordtype">int</span> ii, <span class="keywordtype">double</span> val){</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;        <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[mb][jj]-&gt;setUnitDelta(ii, val);</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;}</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;</div><div class="line"><a name="l00276"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#ab72a0bebc4933c5e495636fe15d33982">  276</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#ab72a0bebc4933c5e495636fe15d33982">NeuralNetwork::initialise</a>(<a class="code" href="classParamsInit.html">ParamsInit</a> parameters)</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;{</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;        <a class="code" href="classNeuralNetwork.html#a5ff4dd9b7b90474cce090c37d7127366">m_sparse</a>            = parameters.<a class="code" href="classParamsInit.html#ab65c93afa1f704b359b25f90f81c1edc">sparse</a>;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;        <a class="code" href="classNeuralNetwork.html#ac6e586b8ab49ef7ca1f07dab6f197f6c">m_sparsityParameter</a> = parameters.<a class="code" href="classParamsInit.html#aa065f164bd6831a5cc6ecb0ee5234466">sparsityParameter</a>;</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;        <a class="code" href="classNeuralNetwork.html#a754d963a6f58aee1e253f64d266ab487">m_dropOut</a>           = parameters.<a class="code" href="classParamsInit.html#aa76f649c6aa95c27f13bc382d3ea46b7">dropOut</a>;</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;        <a class="code" href="classNeuralNetwork.html#accd035b1b93fd424025aeb4b40a31394">m_statsFlag</a>         = <span class="keyword">static_cast&lt;</span><a class="code" href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5">Flag</a><span class="keyword">&gt;</span>(parameters.<a class="code" href="classParamsInit.html#aebf6eb0407471bda84bcb1a3c4a0ea12">statsFlag</a>);</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;        <a class="code" href="classNeuralNetwork.html#ad29fd15c4f0fc4c8fd214b4e815093b9">m_miniBatch</a>         = parameters.<a class="code" href="classParamsInit.html#a5b75660e32158581daeb48a8b648c19a">miniBatch</a>;</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;        <a class="code" href="classNeuralNetwork.html#a1efaefc2c42a3d309c0b5e4a80a55f52">m_numberLayers</a>      = parameters.<a class="code" href="classParamsInit.html#a290d2b18df1f4b1ceba37d2882ad2338">numbLayers</a>;</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;        <a class="code" href="classNeuralNetwork.html#a8940dc6859b38907717cfec54e0929b1">m_momentum</a>          = parameters.<a class="code" href="classParamsInit.html#accff049590c6fb6e86cf2152e8c0a1b5">momentum</a>;</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;        <a class="code" href="classNeuralNetwork.html#a30141464584fc2cc51599ffec4ce8dd8">m_adaGrad</a>           = parameters.<a class="code" href="classParamsInit.html#a1367327b42e60bab2e2ac1f1c74fb8ec">adaGrad</a>;</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;        <a class="code" href="classNeuralNetwork.html#ae4f1fb12e7f5df8dac69abda6fe4d141">m_itTest</a>            = parameters.<a class="code" href="classParamsInit.html#af362ca101eef0ea95d5d63654f22f33b">numbItTest</a>;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;        <a class="code" href="classNeuralNetwork.html#af7766960680b9a413ee4b36acad1e83d">m_flagFast</a>          = (<a class="code" href="classNeuralNetwork.html#a8940dc6859b38907717cfec54e0929b1">m_momentum</a> == 0.0 &amp;&amp; <a class="code" href="classNeuralNetwork.html#a30141464584fc2cc51599ffec4ce8dd8">m_adaGrad</a> == 0.0) ? <a class="code" href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5ab40dedbb237d7d5e7aeef947a8f1cbc6">enabled</a> : <a class="code" href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5a0a2addaf6a0e180369ecaecb25f84d64">disabled</a>;</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;        <a class="code" href="classNeuralNetwork.html#a296fef6f667d2bcf1080a16c8c3aceb2">m_objective</a>.<a class="code" href="classObjective.html#a2241206a261b91770ff4f58385becf57">initialise</a>(parameters);</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;        <span class="comment">//Layers sizes</span></div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a1efaefc2c42a3d309c0b5e4a80a55f52">m_numberLayers</a>; ++ii){</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;                <a class="code" href="classNeuralNetwork.html#a91b00cd0bb975be91e76eb13ffcfe78f">m_layersSizeVec</a>.push_back(parameters.<a class="code" href="classParamsInit.html#aeee8365494660fa642a057d5497d46e1">layersVec</a>.at(ii));</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;        }</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        <span class="comment">//Sparsity set</span></div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classNeuralNetwork.html#a5ff4dd9b7b90474cce090c37d7127366">m_sparse</a> != 0.0 &amp;&amp; m_numberLayers == 3){</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;                <a class="code" href="classNeuralNetwork.html#a257969584b79a83070b07462b1ec7fb2">m_avUnits</a>.resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(1)+1, 0.0);</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;        }</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;       </div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;        <span class="comment">//Layers</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#ad29fd15c4f0fc4c8fd214b4e815093b9">m_miniBatch</a>; ++ii){</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;                <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>.push_back(vector&lt; Layer *&gt;());</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a1efaefc2c42a3d309c0b5e4a80a55f52">m_numberLayers</a>; ++jj){</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;                        <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[ii].push_back(<span class="keyword">new</span> <a class="code" href="classLayer.html">Layer</a>((<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(jj)+1),parameters.<a class="code" href="classParamsInit.html#aa95e42f8c7f50d5ed9186dd2cb4f07aa">actVec</a>.at(jj)));</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;                }</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    }</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;<span class="comment">        /// Drop out initialise </span></div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment"></span>        <a class="code" href="classNeuralNetwork.html#a4e078c8f704a0118f9ed9457b5e6c74d">initialiseDropOut</a>();</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;<span class="comment">        /// Stats hidden units initialise</span></div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="comment"></span>        <a class="code" href="classNeuralNetwork.html#ae27621b39d0afef732ca36e5ab0a6b73">initialiseStatsHiddenUnits</a>();</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;<span class="comment">        /// Bias set</span></div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;<span class="comment"></span>        <a class="code" href="classNeuralNetwork.html#ae8bd77cbaa88df5152db8a745254141c">initialiseDeltaBias</a>(parameters);</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;<span class="comment"></span></div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;<span class="comment">        /// Function to Initialise Weights</span></div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;<span class="comment"></span>        <a class="code" href="classNeuralNetwork.html#a36525085d71d9aa8d755e5e19ebae7cc">initialiseWeights</a>(parameters);</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;        <a class="code" href="classNeuralNetwork.html#ac447314a2315cd10f63b0b330857024a">m_sumDelta</a>.resize(16,0.0);</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;}</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;</div><div class="line"><a name="l00327"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#ae8bd77cbaa88df5152db8a745254141c">  327</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#ae8bd77cbaa88df5152db8a745254141c">NeuralNetwork::initialiseDeltaBias</a>(<a class="code" href="classParamsInit.html">ParamsInit</a> parameters){</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;        <span class="comment">// Go through all mini-batches</span></div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#ad29fd15c4f0fc4c8fd214b4e815093b9">m_miniBatch</a>; ++jj){</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;                <span class="comment">// Go through all layers</span></div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a1efaefc2c42a3d309c0b5e4a80a55f52">m_numberLayers</a>; ++ii){</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;                        <span class="comment">//Set all deltas to 0</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ff = 0; ff&lt;<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii); ++ff){</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;                <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[jj][ii]-&gt;setUnitDelta(ff,0.0);</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;            }</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                        <span class="comment">//set all biases</span></div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;            <a class="code" href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">m_layers</a>[jj][ii]-&gt;setUnitOutput(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii),parameters.<a class="code" href="classParamsInit.html#a31710ca6cd4d0d80f994b45554ba00b0">bias</a>);</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;        }</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;    }</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;}</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;</div><div class="line"><a name="l00344"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a4e078c8f704a0118f9ed9457b5e6c74d">  344</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#a4e078c8f704a0118f9ed9457b5e6c74d">NeuralNetwork::initialiseDropOut</a>(){</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;        <span class="comment">// Allocate memory for the drop out vectors</span></div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;        <a class="code" href="classNeuralNetwork.html#a456d6c273c0bd4f160f4d20f8b26f37b">m_dropOutVec</a>.resize(<a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1);</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1; ++ii){</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                <a class="code" href="classNeuralNetwork.html#a456d6c273c0bd4f160f4d20f8b26f37b">m_dropOutVec</a>[ii].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1),1.0);        </div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;        }</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;        <span class="comment">// If there is a drop out rate</span></div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classNeuralNetwork.html#a754d963a6f58aee1e253f64d266ab487">m_dropOut</a> != 0.0){</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;                <span class="comment">// go through the middle layers (not touching output and input)</span></div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-2; ++ii){</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;                        <span class="comment">// set #unitsInTheL*dropOutRate to 0</span></div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;                        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj&lt;(int)(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1)*<a class="code" href="classNeuralNetwork.html#a754d963a6f58aee1e253f64d266ab487">m_dropOut</a>);++jj){</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;                                <a class="code" href="classNeuralNetwork.html#a456d6c273c0bd4f160f4d20f8b26f37b">m_dropOutVec</a>[ii][jj] = 0.0;</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;                        }</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;                }</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;        }</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;}</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;</div><div class="line"><a name="l00366"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#ae27621b39d0afef732ca36e5ab0a6b73">  366</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#ae27621b39d0afef732ca36e5ab0a6b73">NeuralNetwork::initialiseStatsHiddenUnits</a>(){</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;        <span class="comment">// If gathering statistics</span></div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;        <span class="keywordflow">if</span> (<a class="code" href="classNeuralNetwork.html#accd035b1b93fd424025aeb4b40a31394">m_statsFlag</a> == <a class="code" href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5ab40dedbb237d7d5e7aeef947a8f1cbc6">enabled</a>){</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;                <span class="comment">// Allocate memory for the middle layers only</span></div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;                <a class="code" href="classNeuralNetwork.html#a15f7c03ca694dadc97a4290711ca2101">m_statsHiddenUnits</a>.resize(<a class="code" href="classNeuralNetwork.html#a1efaefc2c42a3d309c0b5e4a80a55f52">m_numberLayers</a>-2);</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0 ; ii &lt; <a class="code" href="classNeuralNetwork.html#a1efaefc2c42a3d309c0b5e4a80a55f52">m_numberLayers</a>-2; ++ii){</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;                       <a class="code" href="classNeuralNetwork.html#a15f7c03ca694dadc97a4290711ca2101">m_statsHiddenUnits</a>[ii].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1),0.0);             </div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;                }</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;        } </div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;}</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;</div><div class="line"><a name="l00382"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a36525085d71d9aa8d755e5e19ebae7cc">  382</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#a36525085d71d9aa8d755e5e19ebae7cc">NeuralNetwork::initialiseWeights</a>(<a class="code" href="classParamsInit.html">ParamsInit</a> parameters){</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;        <span class="comment">// Get the numer of weight layers</span></div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;        <span class="keywordtype">int</span> numberWeights = <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>() - 1;</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;        <span class="comment">// Allocate memory</span></div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;        <a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>.resize(numberWeights);</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;        <a class="code" href="classNeuralNetwork.html#a9ac6bc441d6e2bfe7521d0b23ac8efdb">m_weightsMinCp</a>.resize(numberWeights);</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;        <a class="code" href="classNeuralNetwork.html#a4345c084a3e1f604a3757e3b1ae3ad54">m_momentumArr</a>.resize(numberWeights);</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;        <a class="code" href="classNeuralNetwork.html#a0b6c7ff6e00c4f91e684217be91b0a28">m_sumDeltaArr</a>.resize(numberWeights);</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0; ii &lt; numberWeights; ++ii) {</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;        <a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>[ii].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1));</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;                <a class="code" href="classNeuralNetwork.html#a9ac6bc441d6e2bfe7521d0b23ac8efdb">m_weightsMinCp</a>[ii].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1));</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;        <a class="code" href="classNeuralNetwork.html#a4345c084a3e1f604a3757e3b1ae3ad54">m_momentumArr</a>[ii].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1));</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;                <a class="code" href="classNeuralNetwork.html#a0b6c7ff6e00c4f91e684217be91b0a28">m_sumDeltaArr</a>[ii].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1));</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt;<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1); ++jj){</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;                        <a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>[ii][jj].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii)+1);</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;                        <a class="code" href="classNeuralNetwork.html#a9ac6bc441d6e2bfe7521d0b23ac8efdb">m_weightsMinCp</a>[ii][jj].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii)+1);</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;                        <a class="code" href="classNeuralNetwork.html#a4345c084a3e1f604a3757e3b1ae3ad54">m_momentumArr</a>[ii][jj].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii)+1);</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;                        <a class="code" href="classNeuralNetwork.html#a0b6c7ff6e00c4f91e684217be91b0a28">m_sumDeltaArr</a>[ii][jj].resize(<a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii)+1);</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;        }</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;    }</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;        <span class="comment">// Set the randomness</span></div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;        srand(time(NULL));</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;        <span class="comment">// Go through all weights</span></div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> ii = 0;ii &lt; numberWeights; ++ii){</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a6e03934244dc6512a2d7a481cce51ffc">getLayer</a>(0,ii+1)-&gt;<a class="code" href="classLayer.html#a317562411932be9533c13d20c2890596">getNumbUnits</a>(); ++jj){</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> kk= 0; kk&lt;<a class="code" href="classNeuralNetwork.html#a6e03934244dc6512a2d7a481cce51ffc">getLayer</a>(0,ii)-&gt;<a class="code" href="classLayer.html#a317562411932be9533c13d20c2890596">getNumbUnits</a>()+1; ++kk){</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;                                <span class="comment">// Random number</span></div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;                        <span class="keywordtype">double</span> r = static_cast &lt;<span class="keywordtype">double</span>&gt; (rand()) / static_cast &lt;double&gt; (RAND_MAX);</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;                                <span class="comment">// Scale the random number</span></div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;                        (<a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>)[ii][jj][kk] =(-1.0+2.0*r)*parameters.<a class="code" href="classParamsInit.html#a2258ae5b7eb9489ca58421ac674e012b">weightMagnitude</a>*parameters.<a class="code" href="classParamsInit.html#a5583548cf1c2400d0e6260fc5f757957">randomFlag</a>+(1.0-parameters.<a class="code" href="classParamsInit.html#a5583548cf1c2400d0e6260fc5f757957">randomFlag</a>)*parameters.<a class="code" href="classParamsInit.html#a2258ae5b7eb9489ca58421ac674e012b">weightMagnitude</a>;</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;                                <span class="comment">// Set other arrays to 0</span></div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;                                (<a class="code" href="classNeuralNetwork.html#a4345c084a3e1f604a3757e3b1ae3ad54">m_momentumArr</a>)[ii][jj][kk]  = 0.0;</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;                                (<a class="code" href="classNeuralNetwork.html#a0b6c7ff6e00c4f91e684217be91b0a28">m_sumDeltaArr</a>)[ii][jj][kk]  = 0.0;</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;                                (<a class="code" href="classNeuralNetwork.html#a9ac6bc441d6e2bfe7521d0b23ac8efdb">m_weightsMinCp</a>)[ii][jj][kk] = 0.0;</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;            }</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;        }</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;    }</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;}</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;</div><div class="line"><a name="l00431"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a77e3c1107530a1cb28021c7c2864c81f">  431</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classNeuralNetwork.html#a77e3c1107530a1cb28021c7c2864c81f">NeuralNetwork::initWeightsFromFile</a>(std::string folderName){</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;        <span class="comment">// Go through all layers of weights</span></div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;        <span class="keywordflow">for</span>( <span class="keywordtype">int</span> ii = 0; ii &lt; <a class="code" href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">getNumbLayers</a>()-1; ++ii){</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;                <span class="comment">// Open the file containing required weights</span></div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;                std::string s = std::to_string(ii);</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;                std::string fileName = folderName+<span class="stringliteral">&quot;/weights&quot;</span>+s+<span class="stringliteral">&quot;.dat&quot;</span>;</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;                std::fstream myfilewin(fileName, std::ios_base::in);</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;                </div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;</div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;                <span class="comment">// If file is fine</span></div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;                <span class="keywordflow">if</span> (myfilewin.good()){</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;                        <span class="comment">// Read the parameters</span></div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;                        <span class="keywordtype">int</span> sizeii,sizeiip1,tmp;</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;                        myfilewin&gt;&gt;sizeii;</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;                        myfilewin&gt;&gt;sizeiip1;</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;                        myfilewin&gt;&gt;tmp;</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;                        myfilewin&gt;&gt;tmp;</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;                        myfilewin&gt;&gt;tmp;</div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;                        <span class="comment">// Check whether dimentions in the file are the same as used in the setting </span></div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;                        <span class="keywordflow">if</span> (sizeiip1 == <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1) &amp;&amp; sizeii == <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii)+1){</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;                                <span class="comment">// Read the weights from the file intro the variable</span></div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;                                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> jj = 0; jj &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii+1); ++jj){</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;                                        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> kk= 0; kk &lt; <a class="code" href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">getLayerNumbU</a>(ii)+1; ++kk){</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;                                        myfilewin &gt;&gt; <a class="code" href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">m_weights</a>[ii][jj][kk];</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;                                         }</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;                                }</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;                                myfilewin.close();</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;                        }<span class="keywordflow">else</span>{</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;                                printf(<span class="stringliteral">&quot;Input dimentions of the weights do not match\n&quot;</span>);</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;                                exit(0);</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;                        }</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;                }<span class="keywordflow">else</span>{</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;                        printf(<span class="stringliteral">&quot;Scipping weights %d\n&quot;</span>, ii);</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;                }</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;        }</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;        std::cout&lt;&lt;<span class="stringliteral">&quot;Inititlaised weights from folder::&quot;</span>&lt;&lt;folderName&lt;&lt;<span class="stringliteral">&quot;\n&quot;</span>;</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;}</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;</div><div class="line"><a name="l00476"></a><span class="lineno"><a class="line" href="classNeuralNetwork.html#a65475a7d7b05d302392333302626b2f8">  476</a></span>&#160;<a class="code" href="classNeuralNetwork.html#a65475a7d7b05d302392333302626b2f8">NeuralNetwork::~NeuralNetwork</a>(){</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;}</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;</div><div class="ttc" id="classNeuralNetwork_html_a30196e8390fead450b9495b3a782b198"><div class="ttname"><a href="classNeuralNetwork.html#a30196e8390fead450b9495b3a782b198">NeuralNetwork::makeWeightCpy</a></div><div class="ttdeci">int makeWeightCpy()</div><div class="ttdoc">A function called when local minimum in the validation error is achieved, to store the combination of...</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00021">neuralnetwork.cpp:21</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_accce4a7728e89a009a9d4ca1758c9b9d"><div class="ttname"><a href="classNeuralNetwork.html#accce4a7728e89a009a9d4ca1758c9b9d">NeuralNetwork::NeuralNetwork</a></div><div class="ttdeci">NeuralNetwork()</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00003">neuralnetwork.cpp:3</a></div></div>
<div class="ttc" id="classParamsInit_html_aa065f164bd6831a5cc6ecb0ee5234466"><div class="ttname"><a href="classParamsInit.html#aa065f164bd6831a5cc6ecb0ee5234466">ParamsInit::sparsityParameter</a></div><div class="ttdeci">double sparsityParameter</div><div class="ttdoc">The maximum value of the output neurons expected. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00068">ParamsInit.h:68</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a77e3c1107530a1cb28021c7c2864c81f"><div class="ttname"><a href="classNeuralNetwork.html#a77e3c1107530a1cb28021c7c2864c81f">NeuralNetwork::initWeightsFromFile</a></div><div class="ttdeci">void initWeightsFromFile(std::string path)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00431">neuralnetwork.cpp:431</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a15f7c03ca694dadc97a4290711ca2101"><div class="ttname"><a href="classNeuralNetwork.html#a15f7c03ca694dadc97a4290711ca2101">NeuralNetwork::m_statsHiddenUnits</a></div><div class="ttdeci">vector&lt; vector&lt; float &gt; &gt; m_statsHiddenUnits</div><div class="ttdoc">Matrix to hold the stats about output of the hidden units. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00083">NeuralNetwork.h:83</a></div></div>
<div class="ttc" id="classLayer_html_a317562411932be9533c13d20c2890596"><div class="ttname"><a href="classLayer.html#a317562411932be9533c13d20c2890596">Layer::getNumbUnits</a></div><div class="ttdeci">int getNumbUnits() const </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00063">Layer.h:63</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a1efaefc2c42a3d309c0b5e4a80a55f52"><div class="ttname"><a href="classNeuralNetwork.html#a1efaefc2c42a3d309c0b5e4a80a55f52">NeuralNetwork::m_numberLayers</a></div><div class="ttdeci">int m_numberLayers</div><div class="ttdoc">Number of layers in the neural network. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00044">NeuralNetwork.h:44</a></div></div>
<div class="ttc" id="classLayer_html"><div class="ttname"><a href="classLayer.html">Layer</a></div><div class="ttdoc">Encapsulates information and functions associated with layers. </div><div class="ttdef"><b>Definition:</b> <a href="Layer_8h_source.html#l00019">Layer.h:19</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a30141464584fc2cc51599ffec4ce8dd8"><div class="ttname"><a href="classNeuralNetwork.html#a30141464584fc2cc51599ffec4ce8dd8">NeuralNetwork::m_adaGrad</a></div><div class="ttdeci">float m_adaGrad</div><div class="ttdoc">Magnitude of the adaptive gradient [0;1) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00059">NeuralNetwork.h:59</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ab72a0bebc4933c5e495636fe15d33982"><div class="ttname"><a href="classNeuralNetwork.html#ab72a0bebc4933c5e495636fe15d33982">NeuralNetwork::initialise</a></div><div class="ttdeci">void initialise(ParamsInit parameters)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00276">neuralnetwork.cpp:276</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a660717474efe687f8b7b4bfadd643fee"><div class="ttname"><a href="classNeuralNetwork.html#a660717474efe687f8b7b4bfadd643fee">NeuralNetwork::getWeightO</a></div><div class="ttdeci">double getWeightO(int ii, int jj, int kk) const </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00246">NeuralNetwork.h:246</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a5009762781007f09860915f307701a60"><div class="ttname"><a href="classNeuralNetwork.html#a5009762781007f09860915f307701a60">NeuralNetwork::m_flagSwapped</a></div><div class="ttdeci">bool m_flagSwapped</div><div class="ttdoc">Flag to mark whether the weights have been swapped (i.e. local minimum reached) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00041">NeuralNetwork.h:41</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a49f0a71b2cfd1bd2a4af986354fa103c"><div class="ttname"><a href="classNeuralNetwork.html#a49f0a71b2cfd1bd2a4af986354fa103c">NeuralNetwork::deltaCompute</a></div><div class="ttdeci">double deltaCompute(int mb)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00212">neuralnetwork.cpp:212</a></div></div>
<div class="ttc" id="classParamsInit_html_a1367327b42e60bab2e2ac1f1c74fb8ec"><div class="ttname"><a href="classParamsInit.html#a1367327b42e60bab2e2ac1f1c74fb8ec">ParamsInit::adaGrad</a></div><div class="ttdeci">double adaGrad</div><div class="ttdoc">AdaGrad - ranges from [0;1]. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00056">ParamsInit.h:56</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a456d6c273c0bd4f160f4d20f8b26f37b"><div class="ttname"><a href="classNeuralNetwork.html#a456d6c273c0bd4f160f4d20f8b26f37b">NeuralNetwork::m_dropOutVec</a></div><div class="ttdeci">vector&lt; vector&lt; double &gt; &gt; m_dropOutVec</div><div class="ttdoc">Vector with elements 1 and 0 marking the neurons set to 0. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00092">NeuralNetwork.h:92</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a2a84fe4a996154130853f031c6e475aa"><div class="ttname"><a href="classNeuralNetwork.html#a2a84fe4a996154130853f031c6e475aa">NeuralNetwork::setLayerUDelta</a></div><div class="ttdeci">void setLayerUDelta(int mb, int la, int u, double val)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00271">neuralnetwork.cpp:271</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a9d80cfaedb341a1a94e5b932665904d4"><div class="ttname"><a href="classNeuralNetwork.html#a9d80cfaedb341a1a94e5b932665904d4">NeuralNetwork::backPropagateU</a></div><div class="ttdeci">double backPropagateU(int mb, int la, int ii)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00251">neuralnetwork.cpp:251</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ae3d909ef30a5c179a236571e126aa841"><div class="ttname"><a href="classNeuralNetwork.html#ae3d909ef30a5c179a236571e126aa841">NeuralNetwork::feedforward</a></div><div class="ttdeci">int feedforward(int mb)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00049">neuralnetwork.cpp:49</a></div></div>
<div class="ttc" id="classParamsInit_html_aa95e42f8c7f50d5ed9186dd2cb4f07aa"><div class="ttname"><a href="classParamsInit.html#aa95e42f8c7f50d5ed9186dd2cb4f07aa">ParamsInit::actVec</a></div><div class="ttdeci">vector&lt; int &gt; actVec</div><div class="ttdoc">Vector holding the activation functions. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00161">ParamsInit.h:161</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a4345c084a3e1f604a3757e3b1ae3ad54"><div class="ttname"><a href="classNeuralNetwork.html#a4345c084a3e1f604a3757e3b1ae3ad54">NeuralNetwork::m_momentumArr</a></div><div class="ttdeci">vector&lt; vector&lt; vector&lt; double &gt; &gt; &gt; m_momentumArr</div><div class="ttdoc">Holding momentum for each weight. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00101">NeuralNetwork.h:101</a></div></div>
<div class="ttc" id="classObjective_html_a91b745efca74c55eb1415bdc101c0c8c"><div class="ttname"><a href="classObjective.html#a91b745efca74c55eb1415bdc101c0c8c">Objective::getLSError</a></div><div class="ttdeci">double getLSError(double target, double predicted, int position)</div><div class="ttdef"><b>Definition:</b> <a href="objective_8cpp_source.html#l00133">objective.cpp:133</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ae4f1fb12e7f5df8dac69abda6fe4d141"><div class="ttname"><a href="classNeuralNetwork.html#ae4f1fb12e7f5df8dac69abda6fe4d141">NeuralNetwork::m_itTest</a></div><div class="ttdeci">int m_itTest</div><div class="ttdoc">Number of test iterations. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00050">NeuralNetwork.h:50</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ac447314a2315cd10f63b0b330857024a"><div class="ttname"><a href="classNeuralNetwork.html#ac447314a2315cd10f63b0b330857024a">NeuralNetwork::m_sumDelta</a></div><div class="ttdeci">vector&lt; double &gt; m_sumDelta</div><div class="ttdoc">Vector used for OpenMP to store calculations produced by different threads. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00089">NeuralNetwork.h:89</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a257969584b79a83070b07462b1ec7fb2"><div class="ttname"><a href="classNeuralNetwork.html#a257969584b79a83070b07462b1ec7fb2">NeuralNetwork::m_avUnits</a></div><div class="ttdeci">vector&lt; double &gt; m_avUnits</div><div class="ttdoc">Vector to hold regularization for the sparse autoencoder. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00086">NeuralNetwork.h:86</a></div></div>
<div class="ttc" id="classObjective_html_a2241206a261b91770ff4f58385becf57"><div class="ttname"><a href="classObjective.html#a2241206a261b91770ff4f58385becf57">Objective::initialise</a></div><div class="ttdeci">void initialise(ParamsInit parameters)</div><div class="ttdef"><b>Definition:</b> <a href="objective_8cpp_source.html#l00003">objective.cpp:3</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a4c1c6e488b842002a6d327726ff92dc5a0a2addaf6a0e180369ecaecb25f84d64"><div class="ttname"><a href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5a0a2addaf6a0e180369ecaecb25f84d64">NeuralNetwork::disabled</a></div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00032">NeuralNetwork.h:32</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_aff3f167f69f75a74ce3c425b8783d321"><div class="ttname"><a href="classNeuralNetwork.html#aff3f167f69f75a74ce3c425b8783d321">NeuralNetwork::deltaComputeNodeParallel</a></div><div class="ttdeci">double deltaComputeNodeParallel(int mb)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00133">neuralnetwork.cpp:133</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a5ff4dd9b7b90474cce090c37d7127366"><div class="ttname"><a href="classNeuralNetwork.html#a5ff4dd9b7b90474cce090c37d7127366">NeuralNetwork::m_sparse</a></div><div class="ttdeci">double m_sparse</div><div class="ttdoc">Magnitude of the penalty. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00068">NeuralNetwork.h:68</a></div></div>
<div class="ttc" id="classParamsInit_html_aeee8365494660fa642a057d5497d46e1"><div class="ttname"><a href="classParamsInit.html#aeee8365494660fa642a057d5497d46e1">ParamsInit::layersVec</a></div><div class="ttdeci">vector&lt; int &gt; layersVec</div><div class="ttdoc">Vector holding the sizes of the layers. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00158">ParamsInit.h:158</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a9ac6bc441d6e2bfe7521d0b23ac8efdb"><div class="ttname"><a href="classNeuralNetwork.html#a9ac6bc441d6e2bfe7521d0b23ac8efdb">NeuralNetwork::m_weightsMinCp</a></div><div class="ttdeci">vector&lt; vector&lt; vector&lt; double &gt; &gt; &gt; m_weightsMinCp</div><div class="ttdoc">Cube of weights with which local minimum is achieved. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00098">NeuralNetwork.h:98</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a715c7cc10103a070b270c44b25924608"><div class="ttname"><a href="classNeuralNetwork.html#a715c7cc10103a070b270c44b25924608">NeuralNetwork::getNumbLayers</a></div><div class="ttdeci">int getNumbLayers() const </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00232">NeuralNetwork.h:232</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ad489169464f3a6e827e6fb5de4419061"><div class="ttname"><a href="classNeuralNetwork.html#ad489169464f3a6e827e6fb5de4419061">NeuralNetwork::m_weights</a></div><div class="ttdeci">vector&lt; vector&lt; vector&lt; double &gt; &gt; &gt; m_weights</div><div class="ttdoc">Cube of weights. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00095">NeuralNetwork.h:95</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a4e078c8f704a0118f9ed9457b5e6c74d"><div class="ttname"><a href="classNeuralNetwork.html#a4e078c8f704a0118f9ed9457b5e6c74d">NeuralNetwork::initialiseDropOut</a></div><div class="ttdeci">void initialiseDropOut()</div><div class="ttdoc">A function to initialise the vectors holding positions of the nodes to be set to 0. </div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00344">neuralnetwork.cpp:344</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a91b00cd0bb975be91e76eb13ffcfe78f"><div class="ttname"><a href="classNeuralNetwork.html#a91b00cd0bb975be91e76eb13ffcfe78f">NeuralNetwork::m_layersSizeVec</a></div><div class="ttdeci">vector&lt; int &gt; m_layersSizeVec</div><div class="ttdoc">Vector to hold the sizes of layers. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00080">NeuralNetwork.h:80</a></div></div>
<div class="ttc" id="classParamsInit_html_accff049590c6fb6e86cf2152e8c0a1b5"><div class="ttname"><a href="classParamsInit.html#accff049590c6fb6e86cf2152e8c0a1b5">ParamsInit::momentum</a></div><div class="ttdeci">double momentum</div><div class="ttdoc">Momentum - ranges from [0;1]. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00053">ParamsInit.h:53</a></div></div>
<div class="ttc" id="classParamsInit_html_a5b75660e32158581daeb48a8b648c19a"><div class="ttname"><a href="classParamsInit.html#a5b75660e32158581daeb48a8b648c19a">ParamsInit::miniBatch</a></div><div class="ttdeci">int miniBatch</div><div class="ttdoc">Mini-batch. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00074">ParamsInit.h:74</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_af7766960680b9a413ee4b36acad1e83d"><div class="ttname"><a href="classNeuralNetwork.html#af7766960680b9a413ee4b36acad1e83d">NeuralNetwork::m_flagFast</a></div><div class="ttdeci">Flag m_flagFast</div><div class="ttdoc">Flag used to mark whether fast versions of the functions can be used. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00035">NeuralNetwork.h:35</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a0b6c7ff6e00c4f91e684217be91b0a28"><div class="ttname"><a href="classNeuralNetwork.html#a0b6c7ff6e00c4f91e684217be91b0a28">NeuralNetwork::m_sumDeltaArr</a></div><div class="ttdeci">vector&lt; vector&lt; vector&lt; double &gt; &gt; &gt; m_sumDeltaArr</div><div class="ttdoc">Holding deltas for the adaGrad. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00104">NeuralNetwork.h:104</a></div></div>
<div class="ttc" id="classParamsInit_html_ab65c93afa1f704b359b25f90f81c1edc"><div class="ttname"><a href="classParamsInit.html#ab65c93afa1f704b359b25f90f81c1edc">ParamsInit::sparse</a></div><div class="ttdeci">double sparse</div><div class="ttdoc">Magnitude of the penalty. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00071">ParamsInit.h:71</a></div></div>
<div class="ttc" id="classParamsInit_html_a290d2b18df1f4b1ceba37d2882ad2338"><div class="ttname"><a href="classParamsInit.html#a290d2b18df1f4b1ceba37d2882ad2338">ParamsInit::numbLayers</a></div><div class="ttdeci">int numbLayers</div><div class="ttdoc">The number of layers in the neural network. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00083">ParamsInit.h:83</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_af0c6f4203d6c3b823a575954102bdf5d"><div class="ttname"><a href="classNeuralNetwork.html#af0c6f4203d6c3b823a575954102bdf5d">NeuralNetwork::getGrad</a></div><div class="ttdeci">double getGrad(int kk, int jj, int ii)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00256">neuralnetwork.cpp:256</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a3c92371fb8eb9363460223b67f2716f4"><div class="ttname"><a href="classNeuralNetwork.html#a3c92371fb8eb9363460223b67f2716f4">NeuralNetwork::getLSError</a></div><div class="ttdeci">double getLSError(double target, double predicted, int distFromCenter)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00008">neuralnetwork.cpp:8</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a6e03934244dc6512a2d7a481cce51ffc"><div class="ttname"><a href="classNeuralNetwork.html#a6e03934244dc6512a2d7a481cce51ffc">NeuralNetwork::getLayer</a></div><div class="ttdeci">Layer * getLayer(int mb, int id) const </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00230">NeuralNetwork.h:230</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ad29fd15c4f0fc4c8fd214b4e815093b9"><div class="ttname"><a href="classNeuralNetwork.html#ad29fd15c4f0fc4c8fd214b4e815093b9">NeuralNetwork::m_miniBatch</a></div><div class="ttdeci">int m_miniBatch</div><div class="ttdoc">Mini-batch size. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00047">NeuralNetwork.h:47</a></div></div>
<div class="ttc" id="classParamsInit_html_af362ca101eef0ea95d5d63654f22f33b"><div class="ttname"><a href="classParamsInit.html#af362ca101eef0ea95d5d63654f22f33b">ParamsInit::numbItTest</a></div><div class="ttdeci">int numbItTest</div><div class="ttdoc">The number of test iterations. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00089">ParamsInit.h:89</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ae27621b39d0afef732ca36e5ab0a6b73"><div class="ttname"><a href="classNeuralNetwork.html#ae27621b39d0afef732ca36e5ab0a6b73">NeuralNetwork::initialiseStatsHiddenUnits</a></div><div class="ttdeci">void initialiseStatsHiddenUnits()</div><div class="ttdoc">Allocate memory for the array holding the statistics about hidden units. </div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00366">neuralnetwork.cpp:366</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a1d0b90f44982811b3e28e3b9a4dfa810"><div class="ttname"><a href="classNeuralNetwork.html#a1d0b90f44982811b3e28e3b9a4dfa810">NeuralNetwork::setDropOut</a></div><div class="ttdeci">int setDropOut()</div><div class="ttdoc">A function to set the values of the drop out (shuffle the vectors) </div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00040">neuralnetwork.cpp:40</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a4c1c6e488b842002a6d327726ff92dc5ab40dedbb237d7d5e7aeef947a8f1cbc6"><div class="ttname"><a href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5ab40dedbb237d7d5e7aeef947a8f1cbc6">NeuralNetwork::enabled</a></div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00032">NeuralNetwork.h:32</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_aeccccbe1b61dec7e4e76bd55bad7e591"><div class="ttname"><a href="classNeuralNetwork.html#aeccccbe1b61dec7e4e76bd55bad7e591">NeuralNetwork::swapWeights</a></div><div class="ttdeci">void swapWeights()</div><div class="ttdoc">A function to swap the weights (current with the save with which the local minimum in the error is ob...</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00015">neuralnetwork.cpp:15</a></div></div>
<div class="ttc" id="classParamsInit_html_aa76f649c6aa95c27f13bc382d3ea46b7"><div class="ttname"><a href="classParamsInit.html#aa76f649c6aa95c27f13bc382d3ea46b7">ParamsInit::dropOut</a></div><div class="ttdeci">double dropOut</div><div class="ttdoc">The drop out rate [0;1]. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00062">ParamsInit.h:62</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_accd035b1b93fd424025aeb4b40a31394"><div class="ttname"><a href="classNeuralNetwork.html#accd035b1b93fd424025aeb4b40a31394">NeuralNetwork::m_statsFlag</a></div><div class="ttdeci">Flag m_statsFlag</div><div class="ttdoc">Flag to mark whether the user wants to gather statistics. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00038">NeuralNetwork.h:38</a></div></div>
<div class="ttc" id="classParamsInit_html_a5583548cf1c2400d0e6260fc5f757957"><div class="ttname"><a href="classParamsInit.html#a5583548cf1c2400d0e6260fc5f757957">ParamsInit::randomFlag</a></div><div class="ttdeci">double randomFlag</div><div class="ttdoc">Randomly set the weight inputs or not. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00047">ParamsInit.h:47</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a3182abfff4d633ac07cdfb35f32169ae"><div class="ttname"><a href="classNeuralNetwork.html#a3182abfff4d633ac07cdfb35f32169ae">NeuralNetwork::getLayerUDelta</a></div><div class="ttdeci">double getLayerUDelta(int mb, int la, int u) const </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00236">NeuralNetwork.h:236</a></div></div>
<div class="ttc" id="classParamsInit_html_aebf6eb0407471bda84bcb1a3c4a0ea12"><div class="ttname"><a href="classParamsInit.html#aebf6eb0407471bda84bcb1a3c4a0ea12">ParamsInit::statsFlag</a></div><div class="ttdeci">int statsFlag</div><div class="ttdoc">Stats flag, if 1, gather the statistics. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00140">ParamsInit.h:140</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a65475a7d7b05d302392333302626b2f8"><div class="ttname"><a href="classNeuralNetwork.html#a65475a7d7b05d302392333302626b2f8">NeuralNetwork::~NeuralNetwork</a></div><div class="ttdeci">virtual ~NeuralNetwork()</div><div class="ttdoc">A virtual destructor. </div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00476">neuralnetwork.cpp:476</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a4c1c6e488b842002a6d327726ff92dc5"><div class="ttname"><a href="classNeuralNetwork.html#a4c1c6e488b842002a6d327726ff92dc5">NeuralNetwork::Flag</a></div><div class="ttdeci">Flag</div><div class="ttdoc">Flag to hold activated and deactivated values. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00032">NeuralNetwork.h:32</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a516fbda3ce38841218d09bb823c17994"><div class="ttname"><a href="classNeuralNetwork.html#a516fbda3ce38841218d09bb823c17994">NeuralNetwork::getLayerNumbU</a></div><div class="ttdeci">int getLayerNumbU(int la) const </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00238">NeuralNetwork.h:238</a></div></div>
<div class="ttc" id="classObjective_html_a83f3cc1fe6d1fefe00b06eb5d27b4e6e"><div class="ttname"><a href="classObjective.html#a83f3cc1fe6d1fefe00b06eb5d27b4e6e">Objective::objective</a></div><div class="ttdeci">double objective(int stage, double target, double predicted)</div><div class="ttdef"><b>Definition:</b> <a href="objective_8cpp_source.html#l00096">objective.cpp:96</a></div></div>
<div class="ttc" id="classParamsInit_html"><div class="ttname"><a href="classParamsInit.html">ParamsInit</a></div><div class="ttdoc">Used to store parameters read in Initialiser. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00017">ParamsInit.h:17</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ae8bd77cbaa88df5152db8a745254141c"><div class="ttname"><a href="classNeuralNetwork.html#ae8bd77cbaa88df5152db8a745254141c">NeuralNetwork::initialiseDeltaBias</a></div><div class="ttdeci">void initialiseDeltaBias(ParamsInit parameters)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00327">neuralnetwork.cpp:327</a></div></div>
<div class="ttc" id="classParamsInit_html_a31710ca6cd4d0d80f994b45554ba00b0"><div class="ttname"><a href="classParamsInit.html#a31710ca6cd4d0d80f994b45554ba00b0">ParamsInit::bias</a></div><div class="ttdeci">double bias</div><div class="ttdoc">Bias. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00044">ParamsInit.h:44</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a8940dc6859b38907717cfec54e0929b1"><div class="ttname"><a href="classNeuralNetwork.html#a8940dc6859b38907717cfec54e0929b1">NeuralNetwork::m_momentum</a></div><div class="ttdeci">float m_momentum</div><div class="ttdoc">Magnitude of the momentum [0;1) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00062">NeuralNetwork.h:62</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_aad8fc497e54c397d3e4e91376e02e939"><div class="ttname"><a href="classNeuralNetwork.html#aad8fc497e54c397d3e4e91376e02e939">NeuralNetwork::feedforwardNodeParallel</a></div><div class="ttdeci">int feedforwardNodeParallel(int mb)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00093">neuralnetwork.cpp:93</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ab2bc4d407ef6b85a0089aaaa600e0fb8"><div class="ttname"><a href="classNeuralNetwork.html#ab2bc4d407ef6b85a0089aaaa600e0fb8">NeuralNetwork::m_layers</a></div><div class="ttdeci">vector&lt; vector&lt; Layer * &gt; &gt; m_layers</div><div class="ttdoc">Matrix of layers (1D - minibatch, 2D - layers) </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00077">NeuralNetwork.h:77</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a36525085d71d9aa8d755e5e19ebae7cc"><div class="ttname"><a href="classNeuralNetwork.html#a36525085d71d9aa8d755e5e19ebae7cc">NeuralNetwork::initialiseWeights</a></div><div class="ttdeci">void initialiseWeights(ParamsInit parameters)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00382">neuralnetwork.cpp:382</a></div></div>
<div class="ttc" id="classParamsInit_html_a2258ae5b7eb9489ca58421ac674e012b"><div class="ttname"><a href="classParamsInit.html#a2258ae5b7eb9489ca58421ac674e012b">ParamsInit::weightMagnitude</a></div><div class="ttdeci">double weightMagnitude</div><div class="ttdoc">The scaling factor for the weights. </div><div class="ttdef"><b>Definition:</b> <a href="ParamsInit_8h_source.html#l00059">ParamsInit.h:59</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_af8a0997a14c97e1fb6ef97d3c132f808"><div class="ttname"><a href="classNeuralNetwork.html#af8a0997a14c97e1fb6ef97d3c132f808">NeuralNetwork::dotProductProp</a></div><div class="ttdeci">void dotProductProp(int mb, int kk, int jj)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00124">neuralnetwork.cpp:124</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a754d963a6f58aee1e253f64d266ab487"><div class="ttname"><a href="classNeuralNetwork.html#a754d963a6f58aee1e253f64d266ab487">NeuralNetwork::m_dropOut</a></div><div class="ttdeci">float m_dropOut</div><div class="ttdoc">Fraction of the units set to 0. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00065">NeuralNetwork.h:65</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_adca7f84b7b063acebef819bae1abbaf7"><div class="ttname"><a href="classNeuralNetwork.html#adca7f84b7b063acebef819bae1abbaf7">NeuralNetwork::dotProduct</a></div><div class="ttdeci">double dotProduct(int mb, int kk, int jj)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00111">neuralnetwork.cpp:111</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ae61ce4f7b97b61398b0087afe6ac6d82"><div class="ttname"><a href="classNeuralNetwork.html#ae61ce4f7b97b61398b0087afe6ac6d82">NeuralNetwork::getLayerUOutput</a></div><div class="ttdeci">double getLayerUOutput(int mb, int la, int u) const </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00240">NeuralNetwork.h:240</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a296fef6f667d2bcf1080a16c8c3aceb2"><div class="ttname"><a href="classNeuralNetwork.html#a296fef6f667d2bcf1080a16c8c3aceb2">NeuralNetwork::m_objective</a></div><div class="ttdeci">Objective m_objective</div><div class="ttdoc">Variable to hold objective function. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00074">NeuralNetwork.h:74</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_a82af0b25c1099ac3818a36911b63e8db"><div class="ttname"><a href="classNeuralNetwork.html#a82af0b25c1099ac3818a36911b63e8db">NeuralNetwork::feedforwardNodeParallelCompSparse</a></div><div class="ttdeci">int feedforwardNodeParallelCompSparse(int mb)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00072">neuralnetwork.cpp:72</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ad5d0e3d069c7ce2fbde30161771ba507"><div class="ttname"><a href="classNeuralNetwork.html#ad5d0e3d069c7ce2fbde30161771ba507">NeuralNetwork::setLayerUOutput</a></div><div class="ttdeci">void setLayerUOutput(int mb, int la, int u, double val)</div><div class="ttdef"><b>Definition:</b> <a href="neuralnetwork_8cpp_source.html#l00267">neuralnetwork.cpp:267</a></div></div>
<div class="ttc" id="classNeuralNetwork_html_ac6e586b8ab49ef7ca1f07dab6f197f6c"><div class="ttname"><a href="classNeuralNetwork.html#ac6e586b8ab49ef7ca1f07dab6f197f6c">NeuralNetwork::m_sparsityParameter</a></div><div class="ttdeci">double m_sparsityParameter</div><div class="ttdoc">The maximum value of the output neurons expected. </div><div class="ttdef"><b>Definition:</b> <a href="NeuralNetwork_8h_source.html#l00071">NeuralNetwork.h:71</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
